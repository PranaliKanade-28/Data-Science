{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "DSP_Assignment4_Pranali.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHbb89qHQNIz"
      },
      "source": [
        "# Assignment 4 Dataset:\n",
        "\n",
        "Use fashion-mnist dataset for this assignment. You will have a chance to explore various Deep Learning models in this Assignment.\n",
        "\n",
        "# Dataset description:\n",
        "\n",
        "Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes. Zalando intends Fashion-MNIST to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms. It shares the same image size and structure of training and testing splits.\n",
        "\n",
        "# Labels:\n",
        "Each training and test example is assigned to one of the following labels:\n",
        "\n",
        "0. T-shirt/top\n",
        "1. Trouser\n",
        "2. Pullover\n",
        "3. Dress\n",
        "4. Coat\n",
        "5. Sandal\n",
        "6. Shirt\n",
        "7. Sneaker\n",
        "8. Bag\n",
        "9. Ankle boot\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Assignment 4 - Questions\n",
        "\n",
        "This Assignment focuses on exploring various Deep Learning models(neural networks) and model building. \n",
        "\n",
        "1. Load the fashion-mnist dataset from the tensorflow datasets or download from kaggle(https://www.kaggle.com/zalando-research/fashionmnist)\n",
        "2. Normalize the data - briefly comment why we need to normalize?\n",
        "3. Split the dataset into train(50,000), valid(10,000) and test sets(10,000)\n",
        "4. Reshape the input data to a 2D for MLP(Multi Layer perceptron) and tensor(4d) for CNN(Convolution Neural Network)\n",
        "5. Build a Neural Network Multi-Layer Perceptron Classifier model (you can use sklearn neural network MLP Classifier)\n",
        "6. Experiment with the architecture of the MLP classfier that you already built and report if you seen any improvement in the accuracy\n",
        "7. Build a basic sequential deep learning model(CNN) and compare the accuracy with MLP Classifier\n",
        "8. Experiment with the architecture of CNN and report if you see any improvement in the accuracy\n",
        "9. Evaluate MLPClassifier and CNN using F1 score values and accuracy(only for the best model)\n",
        "10. Explain the paramters to tune to reduce the risk of overfitting in deep learning models\n",
        "10. Optional Explain the meaning of Precision, Recall and F1-Score and why these are used to evaluate Classification models (instead of using Accuracy as a metric). \n",
        "\n",
        "10. optional: Try any advanced deep learning model\n",
        "\n",
        "Submit the .ipynb, and .html \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAcyNdDKGS5a"
      },
      "source": [
        "pip install -U sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XUzNP6NQNI0"
      },
      "source": [
        "# Common imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import normalize"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDdXPc0izsx8"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_P3CFgogTW6"
      },
      "source": [
        "1.\tLoad the fashion-mnist dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFTDwFsmU3-7",
        "outputId": "d0597a01-26f5-4a77-ba9d-603aa9cfa6fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "df = pd.read_csv(\"fashion-mnist_train.csv\")\n",
        "df_t = pd.read_csv(\"fashion-mnist_test.csv\")\n",
        "df.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>pixel39</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "      <th>pixel784</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>105</td>\n",
              "      <td>92</td>\n",
              "      <td>101</td>\n",
              "      <td>107</td>\n",
              "      <td>100</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>...</td>\n",
              "      <td>211</td>\n",
              "      <td>220</td>\n",
              "      <td>214</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>255</td>\n",
              "      <td>222</td>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>44</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>134</td>\n",
              "      <td>162</td>\n",
              "      <td>191</td>\n",
              "      <td>214</td>\n",
              "      <td>163</td>\n",
              "      <td>146</td>\n",
              "      <td>165</td>\n",
              "      <td>79</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>183</td>\n",
              "      <td>112</td>\n",
              "      <td>55</td>\n",
              "      <td>23</td>\n",
              "      <td>72</td>\n",
              "      <td>102</td>\n",
              "      <td>165</td>\n",
              "      <td>160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>163</td>\n",
              "      <td>93</td>\n",
              "      <td>...</td>\n",
              "      <td>171</td>\n",
              "      <td>249</td>\n",
              "      <td>207</td>\n",
              "      <td>197</td>\n",
              "      <td>202</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>21</td>\n",
              "      <td>25</td>\n",
              "      <td>69</td>\n",
              "      <td>52</td>\n",
              "      <td>45</td>\n",
              "      <td>74</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>21</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>187</td>\n",
              "      <td>189</td>\n",
              "      <td>...</td>\n",
              "      <td>230</td>\n",
              "      <td>237</td>\n",
              "      <td>229</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>116</td>\n",
              "      <td>112</td>\n",
              "      <td>136</td>\n",
              "      <td>147</td>\n",
              "      <td>144</td>\n",
              "      <td>121</td>\n",
              "      <td>102</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel1  pixel2  pixel3  ...  pixel781  pixel782  pixel783  pixel784\n",
              "0      2       0       0       0  ...         0         0         0         0\n",
              "1      9       0       0       0  ...         0         0         0         0\n",
              "2      6       0       0       0  ...         0         0         0         0\n",
              "3      0       0       0       0  ...         0         0         0         0\n",
              "4      3       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igCMTz5lGZu2"
      },
      "source": [
        "y=df[['label']]\n",
        "X=df.drop(['label'], axis=1) "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDKaUDKKh0tF"
      },
      "source": [
        "y_test=df_t[['label']]\n",
        "X_test=df_t.drop(['label'], axis=1) "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFuuqj_ygaYp"
      },
      "source": [
        "2.\tNormalize the data - briefly comment why we need to normalize?\n",
        "\n",
        "The goal of normalization is to change the values of numeric columns in the dataset to a common scale, without distorting differences in the ranges of values. It is required only when features have different ranges."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75l6htHWGi1S"
      },
      "source": [
        "X=preprocessing.normalize(X, norm='l2')\n",
        "X_test=preprocessing.normalize(X_test, norm='l2')"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pq9XPa-xgf_9"
      },
      "source": [
        "3.\tSplit the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoTYYovhGq0X"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=1/6, random_state=15)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRqFnS5lhuzd",
        "outputId": "d67d9eb7-31c4-450b-f0c2-797d02b57d5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYTZGQgIN5Ox",
        "outputId": "4f741e5a-253a-4c5b-f581-211351289f0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "some_pic = X_train[0]\n",
        "some_pic_image = some_pic.reshape(28,28)\n",
        "plt.imshow(some_pic_image)\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l38rOYRJ66P6"
      },
      "source": [
        "4.\tReshape the input data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGljm5MBymFZ"
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0],28,28)\n",
        "X_test = X_test.reshape(X_test.shape[0],28,28)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0],28,28)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ym4p-nnYzmGP"
      },
      "source": [
        "5.\tBuild a Neural Network Multi-Layer Perceptron Classifier model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTDYbfn1zktG"
      },
      "source": [
        "y_train = keras.utils.to_categorical(y_train, 10)\n",
        "y_valid = keras.utils.to_categorical(y_valid, 10)\n",
        "y_test = keras.utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIldyvhazjAx"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28,28)))\n",
        "model.add(Dense(256, activation='relu' ,input_shape=(28*28,)))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10, activation='sigmoid'))"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-H17xASz_L3"
      },
      "source": [
        "optim = keras.optimizers.SGD(lr=0.01, momentum=0.950,  nesterov=True)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi19KZS1zjGX"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        " optimizer=optim,\n",
        " metrics=['accuracy'])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbgUmGp1zjKV",
        "outputId": "a6d7538d-d3fb-42b1-f72c-95bf3b52112e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "batch_size=80,\n",
        "epochs=12,\n",
        "verbose=2,\n",
        "validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "625/625 - 3s - loss: 1.4766 - accuracy: 0.4301 - val_loss: 0.7822 - val_accuracy: 0.6922\n",
            "Epoch 2/12\n",
            "625/625 - 3s - loss: 0.7190 - accuracy: 0.7222 - val_loss: 0.5371 - val_accuracy: 0.7920\n",
            "Epoch 3/12\n",
            "625/625 - 3s - loss: 0.5696 - accuracy: 0.7944 - val_loss: 0.4746 - val_accuracy: 0.8238\n",
            "Epoch 4/12\n",
            "625/625 - 3s - loss: 0.5154 - accuracy: 0.8170 - val_loss: 0.4366 - val_accuracy: 0.8406\n",
            "Epoch 5/12\n",
            "625/625 - 3s - loss: 0.4854 - accuracy: 0.8273 - val_loss: 0.4200 - val_accuracy: 0.8428\n",
            "Epoch 6/12\n",
            "625/625 - 3s - loss: 0.4657 - accuracy: 0.8350 - val_loss: 0.4103 - val_accuracy: 0.8470\n",
            "Epoch 7/12\n",
            "625/625 - 3s - loss: 0.4487 - accuracy: 0.8400 - val_loss: 0.3969 - val_accuracy: 0.8560\n",
            "Epoch 8/12\n",
            "625/625 - 3s - loss: 0.4348 - accuracy: 0.8453 - val_loss: 0.3921 - val_accuracy: 0.8573\n",
            "Epoch 9/12\n",
            "625/625 - 3s - loss: 0.4221 - accuracy: 0.8485 - val_loss: 0.3803 - val_accuracy: 0.8595\n",
            "Epoch 10/12\n",
            "625/625 - 3s - loss: 0.4163 - accuracy: 0.8504 - val_loss: 0.3743 - val_accuracy: 0.8630\n",
            "Epoch 11/12\n",
            "625/625 - 3s - loss: 0.4056 - accuracy: 0.8560 - val_loss: 0.3624 - val_accuracy: 0.8654\n",
            "Epoch 12/12\n",
            "625/625 - 3s - loss: 0.3988 - accuracy: 0.8573 - val_loss: 0.3581 - val_accuracy: 0.8676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3MR0uekzjPV",
        "outputId": "fc59314f-f641-4286-a241-861658421f2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Highest Accuracy', score[1])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3478630483150482\n",
            "Highest Accuracy 0.8722000122070312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "af0a0lBP-yZ5"
      },
      "source": [
        "Accuracy for the MLP model 1 is 87.22%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AW1hk8Sm7EkP"
      },
      "source": [
        "6.\tExperiment with the architecture of the MLP classfier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGAvuO8ozjTu"
      },
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Flatten(input_shape=(28,28)))\n",
        "model_2.add(Dense(180, activation='relu' ,input_shape=(28*28,)))\n",
        "model_2.add(Dropout(0.4))\n",
        "model_2.add(Dense(360, activation='relu',))\n",
        "model_2.add(Dropout(0.4))\n",
        "model_2.add(Dense(512, activation='relu',))\n",
        "model_2.add(Dropout(0.4))\n",
        "model_2.add(Dense(10, activation='sigmoid',))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqDMze6CzjXR"
      },
      "source": [
        "model_2.compile(loss='categorical_crossentropy',\n",
        " optimizer=optim,\n",
        " metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59cHLya5zkFi",
        "outputId": "e69fb01b-56b7-4715-826c-fb891b92190c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "history = model_2.fit(X_train, y_train,\n",
        "batch_size=100,\n",
        "epochs=18,\n",
        "verbose=2,\n",
        "validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/18\n",
            "500/500 - 5s - loss: 1.7013 - accuracy: 0.3505 - val_loss: 0.8807 - val_accuracy: 0.6329\n",
            "Epoch 2/18\n",
            "500/500 - 5s - loss: 0.7946 - accuracy: 0.6837 - val_loss: 0.5835 - val_accuracy: 0.7712\n",
            "Epoch 3/18\n",
            "500/500 - 5s - loss: 0.6046 - accuracy: 0.7733 - val_loss: 0.4998 - val_accuracy: 0.8123\n",
            "Epoch 4/18\n",
            "500/500 - 5s - loss: 0.5352 - accuracy: 0.8047 - val_loss: 0.4642 - val_accuracy: 0.8286\n",
            "Epoch 5/18\n",
            "500/500 - 5s - loss: 0.4966 - accuracy: 0.8199 - val_loss: 0.4359 - val_accuracy: 0.8381\n",
            "Epoch 6/18\n",
            "500/500 - 5s - loss: 0.4776 - accuracy: 0.8289 - val_loss: 0.4139 - val_accuracy: 0.8501\n",
            "Epoch 7/18\n",
            "500/500 - 5s - loss: 0.4605 - accuracy: 0.8345 - val_loss: 0.4132 - val_accuracy: 0.8486\n",
            "Epoch 8/18\n",
            "500/500 - 5s - loss: 0.4463 - accuracy: 0.8389 - val_loss: 0.3955 - val_accuracy: 0.8527\n",
            "Epoch 9/18\n",
            "500/500 - 5s - loss: 0.4370 - accuracy: 0.8397 - val_loss: 0.3957 - val_accuracy: 0.8555\n",
            "Epoch 10/18\n",
            "500/500 - 5s - loss: 0.4256 - accuracy: 0.8454 - val_loss: 0.3861 - val_accuracy: 0.8582\n",
            "Epoch 11/18\n",
            "500/500 - 5s - loss: 0.4164 - accuracy: 0.8492 - val_loss: 0.3732 - val_accuracy: 0.8609\n",
            "Epoch 12/18\n",
            "500/500 - 5s - loss: 0.4104 - accuracy: 0.8511 - val_loss: 0.3732 - val_accuracy: 0.8624\n",
            "Epoch 13/18\n",
            "500/500 - 5s - loss: 0.4035 - accuracy: 0.8537 - val_loss: 0.3679 - val_accuracy: 0.8638\n",
            "Epoch 14/18\n",
            "500/500 - 5s - loss: 0.3977 - accuracy: 0.8539 - val_loss: 0.3742 - val_accuracy: 0.8598\n",
            "Epoch 15/18\n",
            "500/500 - 5s - loss: 0.3926 - accuracy: 0.8564 - val_loss: 0.3655 - val_accuracy: 0.8661\n",
            "Epoch 16/18\n",
            "500/500 - 5s - loss: 0.3932 - accuracy: 0.8570 - val_loss: 0.3547 - val_accuracy: 0.8704\n",
            "Epoch 17/18\n",
            "500/500 - 5s - loss: 0.3822 - accuracy: 0.8606 - val_loss: 0.3545 - val_accuracy: 0.8702\n",
            "Epoch 18/18\n",
            "500/500 - 5s - loss: 0.3818 - accuracy: 0.8618 - val_loss: 0.3675 - val_accuracy: 0.8643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbT_6eCfzkCy",
        "outputId": "c1e63916-3ea4-4ae3-ef5b-5bd79502d1e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model_2.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Highest Accuracy', score[1])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.36175110936164856\n",
            "Highest Accuracy 0.8658999800682068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPGMra1p-6lX"
      },
      "source": [
        "Accuracy for MLP model2 is 86.58% which is lesser than first model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srzKi8d7_16"
      },
      "source": [
        "7.\tBuild a basic sequential deep learning model(CNN) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpVhgoYRzjSU"
      },
      "source": [
        "X_train_2 = X_train.reshape(X_train.shape[0],28,28,1)\n",
        "X_test_2 = X_test.reshape(X_test.shape[0],28,28,1)\n",
        "X_valid_2 = X_valid.reshape(X_valid.shape[0],28,28,1)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgC6hJaUzjOK"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Conv2D(filters=80, kernel_size=2, activation='relu', input_shape=(28,28,1))) \n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Conv2D(filters=50, kernel_size=2, activation='relu'))\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model.add(tf.keras.layers.Dropout(0.3))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(300, activation='relu'))\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9-4KxTrzjJB"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adamax',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyFE-061zjFD",
        "outputId": "6c023c07-8f13-4539-ce13-111a531a37cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_2,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=12,\n",
        "         validation_data=(X_valid_2, y_valid))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "782/782 [==============================] - 74s 95ms/step - loss: 0.8502 - accuracy: 0.6833 - val_loss: 0.5733 - val_accuracy: 0.7820\n",
            "Epoch 2/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.5787 - accuracy: 0.7837 - val_loss: 0.4879 - val_accuracy: 0.8219\n",
            "Epoch 3/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.5168 - accuracy: 0.8085 - val_loss: 0.4497 - val_accuracy: 0.8336\n",
            "Epoch 4/12\n",
            "782/782 [==============================] - 78s 100ms/step - loss: 0.4796 - accuracy: 0.8224 - val_loss: 0.4164 - val_accuracy: 0.8462\n",
            "Epoch 5/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.4505 - accuracy: 0.8371 - val_loss: 0.4021 - val_accuracy: 0.8516\n",
            "Epoch 6/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.4302 - accuracy: 0.8430 - val_loss: 0.3816 - val_accuracy: 0.8620\n",
            "Epoch 7/12\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 0.4140 - accuracy: 0.8486 - val_loss: 0.3695 - val_accuracy: 0.8607\n",
            "Epoch 8/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.3983 - accuracy: 0.8553 - val_loss: 0.3590 - val_accuracy: 0.8683\n",
            "Epoch 9/12\n",
            "782/782 [==============================] - 75s 95ms/step - loss: 0.3907 - accuracy: 0.8587 - val_loss: 0.3490 - val_accuracy: 0.8707\n",
            "Epoch 10/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.3812 - accuracy: 0.8619 - val_loss: 0.3408 - val_accuracy: 0.8761\n",
            "Epoch 11/12\n",
            "782/782 [==============================] - 75s 96ms/step - loss: 0.3743 - accuracy: 0.8638 - val_loss: 0.3368 - val_accuracy: 0.8786\n",
            "Epoch 12/12\n",
            "782/782 [==============================] - 79s 101ms/step - loss: 0.3640 - accuracy: 0.8678 - val_loss: 0.3334 - val_accuracy: 0.8767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa1550da7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjZAYnTYzi_U",
        "outputId": "e2e7601d-fba4-4904-944f-afef7475168e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model.evaluate(X_test_2, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Highest Accuracy', score[1])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3193071186542511\n",
            "Highest Accuracy 0.8838000297546387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQM2p3As1xVa",
        "outputId": "15b0b7a3-cd6b-4de7-ca75-e6aa69340bf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "cnn_pred_mnist = model.predict(X_test_2)\n",
        "cnn_pred_mnist = np.argmax(cnn_pred_mnist,axis=1)\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "\n",
        "cnn_f1_mnist = metrics.f1_score(y_true, cnn_pred_mnist, average= \"weighted\")\n",
        "print(\"F1 score: {}\".format(cnn_f1_mnist))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.8826422538760266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlSV5_IW_USV"
      },
      "source": [
        "F1 score for CNN model is .88 and accuracy is 88.38% which is better than previous two MLP models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKa3prBa8GM-"
      },
      "source": [
        "8.\tExperiment with the architecture of CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPpZlMpT1xbB"
      },
      "source": [
        "model_c1 = tf.keras.Sequential()\n",
        "# Must define the input shape in the first layer of the neural network\n",
        "model_c1.add(tf.keras.layers.Conv2D(filters=128, kernel_size=2, activation='relu', input_shape=(28,28,1))) \n",
        "model_c1.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model_c1.add(tf.keras.layers.Dropout(0.3))\n",
        "model_c1.add(tf.keras.layers.Conv2D(filters=256, kernel_size=2, activation='relu'))\n",
        "model_c1.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model_c1.add(tf.keras.layers.Dropout(0.3))\n",
        "model_c1.add(tf.keras.layers.Conv2D(filters=512, kernel_size=2, padding='same', activation='relu'))\n",
        "model_c1.add(tf.keras.layers.MaxPooling2D(pool_size=2))\n",
        "model_c1.add(tf.keras.layers.Dropout(0.3))\n",
        "model_c1.add(tf.keras.layers.Flatten())\n",
        "model_c1.add(tf.keras.layers.Dense(512, activation='relu'))\n",
        "model_c1.add(tf.keras.layers.Dropout(0.5))\n",
        "model_c1.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj64xJCe1xgb"
      },
      "source": [
        "model_c1.compile(loss='categorical_crossentropy',\n",
        "             optimizer='adam',\n",
        "             metrics=['accuracy'])"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qV8DVMm1xq0",
        "outputId": "8b93834a-f87b-44c2-e89f-079453ef0622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_c1.fit(X_train_2,\n",
        "         y_train,\n",
        "         batch_size=64,\n",
        "         epochs=15,\n",
        "         validation_data=(X_valid_2, y_valid))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 [==============================] - 432s 552ms/step - loss: 0.7165 - accuracy: 0.7283 - val_loss: 0.4693 - val_accuracy: 0.8198\n",
            "Epoch 2/15\n",
            "782/782 [==============================] - 429s 549ms/step - loss: 0.4522 - accuracy: 0.8338 - val_loss: 0.3676 - val_accuracy: 0.8656\n",
            "Epoch 3/15\n",
            "782/782 [==============================] - 434s 554ms/step - loss: 0.3924 - accuracy: 0.8557 - val_loss: 0.3352 - val_accuracy: 0.8741\n",
            "Epoch 4/15\n",
            "782/782 [==============================] - 429s 549ms/step - loss: 0.3664 - accuracy: 0.8663 - val_loss: 0.3312 - val_accuracy: 0.8761\n",
            "Epoch 5/15\n",
            "782/782 [==============================] - 427s 546ms/step - loss: 0.3404 - accuracy: 0.8734 - val_loss: 0.2963 - val_accuracy: 0.8928\n",
            "Epoch 6/15\n",
            "782/782 [==============================] - 427s 546ms/step - loss: 0.3272 - accuracy: 0.8798 - val_loss: 0.2882 - val_accuracy: 0.8926\n",
            "Epoch 7/15\n",
            "782/782 [==============================] - 429s 549ms/step - loss: 0.3117 - accuracy: 0.8854 - val_loss: 0.2794 - val_accuracy: 0.8964\n",
            "Epoch 8/15\n",
            "782/782 [==============================] - 424s 543ms/step - loss: 0.2987 - accuracy: 0.8893 - val_loss: 0.2672 - val_accuracy: 0.9008\n",
            "Epoch 9/15\n",
            "782/782 [==============================] - 425s 544ms/step - loss: 0.2861 - accuracy: 0.8941 - val_loss: 0.2585 - val_accuracy: 0.9057\n",
            "Epoch 10/15\n",
            "782/782 [==============================] - 428s 547ms/step - loss: 0.2773 - accuracy: 0.8968 - val_loss: 0.2740 - val_accuracy: 0.9022\n",
            "Epoch 11/15\n",
            "782/782 [==============================] - 436s 557ms/step - loss: 0.2700 - accuracy: 0.8991 - val_loss: 0.2568 - val_accuracy: 0.9050\n",
            "Epoch 12/15\n",
            "782/782 [==============================] - 432s 553ms/step - loss: 0.2617 - accuracy: 0.9016 - val_loss: 0.2626 - val_accuracy: 0.9039\n",
            "Epoch 13/15\n",
            "782/782 [==============================] - 438s 560ms/step - loss: 0.2569 - accuracy: 0.9046 - val_loss: 0.2503 - val_accuracy: 0.9094\n",
            "Epoch 14/15\n",
            "782/782 [==============================] - 434s 555ms/step - loss: 0.2489 - accuracy: 0.9069 - val_loss: 0.2532 - val_accuracy: 0.9065\n",
            "Epoch 15/15\n",
            "782/782 [==============================] - 428s 547ms/step - loss: 0.2438 - accuracy: 0.9085 - val_loss: 0.2341 - val_accuracy: 0.9175\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa15ef81be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXjccm_e8OCS"
      },
      "source": [
        "9.\tEvaluate MLPClassifier and CNN "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctmoZfyy1xeG",
        "outputId": "b51c8376-6280-4e77-ee74-89740fc92329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model_c1.evaluate(X_test_2, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Highest accuracy:', score[1])"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.22002370655536652\n",
            "Highest accuracy: 0.920199990272522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K2LfhWl1xTo",
        "outputId": "f6fc919b-7881-4fa3-ba48-9bb982e2c9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "cnn_pred_mnist = model_c1.predict(X_test_2)\n",
        "cnn_pred_mnist = np.argmax(cnn_pred_mnist,axis=1)\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "\n",
        "cnn_f1_mnist = metrics.f1_score(y_true, cnn_pred_mnist, average= \"weighted\")\n",
        "print(\"F1 score: {}\".format(cnn_f1_mnist))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.919713907792208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6yrMlQ51xSc",
        "outputId": "4a5faf43-01a3-4fa0-e721-1249596a89c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "score = model_2.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Highest accuracy:', score[1])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.36175110936164856\n",
            "Highest accuracy: 0.8658999800682068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4g2L0z91xQU",
        "outputId": "0a65afa7-a337-4e1c-ea79-09fc2ab3b84f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "mlp_pred_mnist = model_2.predict(X_test)\n",
        "mlp_pred_mnist = np.argmax(mlp_pred_mnist,axis=1)\n",
        "y_true = np.argmax(y_test,axis=1)\n",
        "\n",
        "mlp_f1_mnist = metrics.f1_score(y_true, mlp_pred_mnist, average= \"weighted\")\n",
        "print(\"F1 score: {}\".format(mlp_f1_mnist))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score: 0.8680376139336667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri-BMOkYVsm3"
      },
      "source": [
        "Accuracy of CNN is highest with hyperparameter tuning which is 92.01%. Overall accuracy of CNN model is higher compared to MLP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShdMlsRn8SHH"
      },
      "source": [
        "10.\tExplain the paramters to tune to reduce the risk of overfitting \n",
        "\n",
        "We can use Dropout layers, which will randomly remove certain features by setting them to zero. We can use early stopping to avoid overfitting. We can use more data to train the model.Cross validation can help reduce overfitting"
      ]
    }
  ]
}
