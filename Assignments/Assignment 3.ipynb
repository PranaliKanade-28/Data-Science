{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ay6iRqyGmTxh"
   },
   "source": [
    "\n",
    "# Dataset description:\n",
    "\n",
    "https://www.drivendata.org/competitions/57/nepal-earthquake/\n",
    "\n",
    "The dataset mainly consists of information on the buildings' structure and their legal ownership. Each row in the dataset represents a specific building in the region that was hit by Gorkha earthquake.\n",
    "\n",
    "There are 39 columns in this dataset, where the building_id column is a unique and random identifier. The remaining 38 features are described in the section below. Categorical variables have been transformed to random lowercase ascii characters. The appearance of the same character in distinct columns does not imply the same original value.\n",
    "\n",
    "# Target variable:\n",
    "Damage_grade is the target variable we have to classify.\n",
    "\n",
    "\n",
    "# Features:\n",
    "- geo_level_1_id, geo_level_2_id, geo_level_3_id (type: int): geographic region in which building exists, from largest (level 1) to most specific sub-region (level 3). Possible values: level 1: 0-30, level 2: 0-1427, level 3: 0-12567.\n",
    "-\tcount_floors_pre_eq (type: int): number of floors in the building before the earthquake.\n",
    "-\tage (type: int): age of the building in years.\n",
    "-\tarea_percentage (type: int): normalized area of the building footprint.\n",
    "\n",
    "-\theight_percentage (type: int): normalized height of the building footprint.\n",
    "\n",
    "-\tland_surface_condition (type: categorical): surface condition of the land where the building was built. Possible values: n, o, t.\n",
    "-\tfoundation_type (type: categorical): type of foundation used while building. Possible values: h, i, r, u, w.\n",
    "-\troof_type (type: categorical): type of roof used while building. Possible values: n, q, x.\n",
    "-\tground_floor_type (type: categorical): type of the ground floor. Possible values: f, m, v, x, z.\n",
    "-\tother_floor_type (type: categorical): type of constructions used in higher than the ground floors (except of roof). Possible values: j, q, s, x.\n",
    "-\tposition (type: categorical): position of the building. Possible values: j, o, s, t.\n",
    "-\tplan_configuration (type: categorical): building plan configuration. Possible values: a, c, d, f, m, n, o, q, s, u.\n",
    "-\thas_superstructure_adobe_mud (type: binary): flag variable that indicates if the superstructure was made of Adobe/Mud.\n",
    "-\thas_superstructure_mud_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Stone.\n",
    "-\thas_superstructure_stone_flag (type: binary): flag variable that indicates if the superstructure was made of Stone.\n",
    "-\thas_superstructure_cement_mortar_stone (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Stone.\n",
    "-\thas_superstructure_mud_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Mud Mortar - Brick.\n",
    "-\thas_superstructure_cement_mortar_brick (type: binary): flag variable that indicates if the superstructure was made of Cement Mortar - Brick.\n",
    "-\thas_superstructure_timber (type: binary): flag variable that indicates if the superstructure was made of Timber.\n",
    "-\thas_superstructure_bamboo (type: binary): flag variable that indicates if the superstructure was made of Bamboo.\n",
    "-\thas_superstructure_rc_non_engineered (type: binary): flag variable that indicates if the superstructure was made of non-engineered reinforced concrete.\n",
    "-\thas_superstructure_rc_engineered (type: binary): flag variable that indicates if the superstructure was made of engineered reinforced concrete.\n",
    "-\thas_superstructure_other (type: binary): flag variable that indicates if the superstructure was made of any other material.\n",
    "-\tlegal_ownership_status (type: categorical): legal ownership status of the land where building was built. Possible values: a, r, v, w.\n",
    "-\tcount_families (type: int): number of families that live in the building.\n",
    "-\thas_secondary_use (type: binary): flag variable that indicates if the building was used for any secondary purpose.\n",
    "-\thas_secondary_use_agriculture (type: binary): flag variable that indicates if the building was used for agricultural purposes.\n",
    "-\thas_secondary_use_hotel (type: binary): flag variable that indicates if the building was used as a hotel.\n",
    "-\thas_secondary_use_rental (type: binary): flag variable that indicates if the building was used for rental purposes.\n",
    "-\thas_secondary_use_institution (type: binary): flag variable that indicates if the building was used as a location of any institution.\n",
    "-\thas_secondary_use_school (type: binary): flag variable that indicates if the building was used as a school.\n",
    "-\thas_secondary_use_industry (type: binary): flag variable that indicates if the building was used for industrial purposes.\n",
    "-\thas_secondary_use_health_post (type: binary): flag variable that indicates if the building was used as a health post.\n",
    "-\thas_secondary_use_gov_office (type: binary): flag variable that indicates if the building was used fas a government office.\n",
    "-\thas_secondary_use_use_police (type: binary): flag variable that indicates if the building was used as a police station.\n",
    "-\thas_secondary_use_other (type: binary): flag variable that indicates if the building was secondarily used for other purposes.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Assignment 3 - Questions\n",
    "\n",
    "Use the knowledge from Assignment 1 and 2 to do this. This assignment focuses on model building, tuning, hyper-parameter tuning and diagnosing machine learning performance. Please note that running ML models and hyper-parameter search will take significant time\n",
    "\n",
    "This Assignment focuses on data preprocessing and model building. Load the dataset.  In this assignment you need to use both i). Linear SVR Classifier ,ii) Decision Trees iii) Ensemble Learners. Provide your intepretations.\n",
    "\n",
    "0. Take a subset of the dataset(5-10% of the whole dataset **free to do this on whole dataset, given the memory requirements**)), given the nature of the dataset and proceed with the following questions\n",
    "\n",
    "\n",
    "\n",
    "1. List which features you will choose in this model. Write a brief statement: Is it required to consider the repeating features in the model? if independent variables are highly correlated. Select the required columns in the dataframe and drop the others\n",
    "\n",
    "2. Preprocess the data according to your experience with assignment 1 and 2.\n",
    "    1. Convert percentage to value/100 (check which option gives better result, as-is or divided/100)\n",
    "    2. Make an 80-20 stratified split based on the target variable(categorical variable)\n",
    "    3. Show the stratified split on merged dataset, train and test set.(display the ratio of classes on each dataset)\n",
    "    4. Encode the categorical features\n",
    "    5. Standardize the numerical features\n",
    "    \n",
    "3. Build a SVM Classifier, train the model\n",
    "    1. Evaluate your model based on applicable metrics. Show the metric(s) you chose and why you chose this(these) metrics.\n",
    "    2. List the hyper-parameters that can be tuned in SVM Classifier. Explain the meaning of each hyper-parameter. Show the code along with comments on the parameter value chosen (use class presentation, discussion notes, some online reading) and why this value was chosen. Show the improvement you achieved in model accuracy. \n",
    "    3. Plot Learning curve on the optimized model and provide insights\n",
    "4. Build a Decision Tree Classifier, train the model\n",
    "    1. Evaluate your model based on applicable metrics. Show the metric(s) you chose and why you chose this(these) metrics.\n",
    "    2. List the hyper-parameters that can be tuned in Decision Tree model . Show the code along with comments on the parameter value chosen (use class presentation, discussion notes, some online reading) and why this value was chosen. Show the improvement you achieved in model accuracy. \n",
    " \n",
    "5. Compare the Model Evaluation metric of  which model performed better along with reason why you consider so.\n",
    "\n",
    "6. Optional: Submit your predictions to the contest(require the run on whole dataset). You will get a submission score. Use any other models of your choice discusssed in the class and check if you get improved result. Show it here.\n",
    "\n",
    "\n",
    "Submit the following for this assignment: \n",
    "1. .ipynb and .html formats of Jupyter notebook code with outputs and \n",
    "2. Please follow coding standards\n",
    "\n",
    "Note:\n",
    "Missing each of these will take out 0.1 point at each applicable place:\n",
    "1. Using full file path (you can use path=input() to set path and use it in os.chdir())\n",
    "2. Not labeling plots (x-label, y-label, title), not presentable plots (too small/oversized/overflow/unreadbale labels etc)\n",
    "3. Not having observation below each plot, dataframe output, model result/evaluation output where applies. Observation should be pointed, should not be generic statement and should be backed up with technical evidence from the results obtained.\n",
    "4. Not showing each question as markdown, then answer, then observation as markdown\n",
    "5. Printing full/lengthy dataframe\n",
    "6. Importing excess libraries and not using in code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "id": "NNOgwkyKqmwk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "id": "s5yG76oKrbXZ"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train_values.csv\")\n",
    "df_l=pd.read_csv(\"train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "6ZOiML1l9P41",
    "outputId": "40b7e029-1c2f-4333-cf07-6d14138a5f6f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>position</th>\n",
       "      <th>plan_configuration</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>legal_ownership_status</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802906</td>\n",
       "      <td>6</td>\n",
       "      <td>487</td>\n",
       "      <td>12198</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28830</td>\n",
       "      <td>8</td>\n",
       "      <td>900</td>\n",
       "      <td>2812</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>x</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94947</td>\n",
       "      <td>21</td>\n",
       "      <td>363</td>\n",
       "      <td>8973</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>t</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>590882</td>\n",
       "      <td>22</td>\n",
       "      <td>418</td>\n",
       "      <td>10694</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>201944</td>\n",
       "      <td>11</td>\n",
       "      <td>131</td>\n",
       "      <td>1488</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  geo_level_1_id  ...  has_secondary_use_other  damage_grade\n",
       "0       802906               6  ...                        0             3\n",
       "1        28830               8  ...                        0             2\n",
       "2        94947              21  ...                        0             3\n",
       "3       590882              22  ...                        0             2\n",
       "4       201944              11  ...                        0             3\n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 231,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging the datasets using merge function\n",
    "df_merged = pd.merge(df, df_l, how='left')\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "N88jOZ87rq3K",
    "outputId": "baa6275c-4ee0-4a38-bdc9-c2ff03ee347a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23454, 40)"
      ]
     },
     "execution_count": 232,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting 9% subset of dataset\n",
    "df_sub=df_merged.sample(frac=0.09)\n",
    "df_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QgkBL4v8uHNb",
    "outputId": "a90aba3d-80bc-4028-929a-2beb2aa85cea"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>building_id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>-0.004609</td>\n",
       "      <td>-0.004742</td>\n",
       "      <td>-0.014937</td>\n",
       "      <td>-0.007989</td>\n",
       "      <td>-0.001444</td>\n",
       "      <td>-0.004994</td>\n",
       "      <td>-0.012055</td>\n",
       "      <td>0.017126</td>\n",
       "      <td>-0.000483</td>\n",
       "      <td>-0.000758</td>\n",
       "      <td>-0.009615</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>-0.008597</td>\n",
       "      <td>-0.005350</td>\n",
       "      <td>-0.006889</td>\n",
       "      <td>-0.005304</td>\n",
       "      <td>-0.006948</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.008026</td>\n",
       "      <td>0.008090</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>-0.006756</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003080</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.071127</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>-0.090799</td>\n",
       "      <td>-0.013874</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>-0.059720</td>\n",
       "      <td>-0.033513</td>\n",
       "      <td>-0.140193</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>-0.039078</td>\n",
       "      <td>0.135004</td>\n",
       "      <td>0.139619</td>\n",
       "      <td>0.074938</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>-0.011838</td>\n",
       "      <td>-0.017949</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>-0.003183</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.068103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <td>-0.004609</td>\n",
       "      <td>-0.071127</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.055193</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>-0.046722</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>-0.078566</td>\n",
       "      <td>-0.023487</td>\n",
       "      <td>-0.032875</td>\n",
       "      <td>-0.030467</td>\n",
       "      <td>-0.041523</td>\n",
       "      <td>-0.020258</td>\n",
       "      <td>-0.009028</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>-0.012675</td>\n",
       "      <td>-0.034872</td>\n",
       "      <td>-0.005908</td>\n",
       "      <td>-0.021183</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.051701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <td>-0.004742</td>\n",
       "      <td>0.004823</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021786</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>-0.027790</td>\n",
       "      <td>-0.008250</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>-0.018505</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>-0.005648</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>-0.009593</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>-0.016650</td>\n",
       "      <td>-0.011057</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>-0.010094</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>-0.001693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_floors_pre_eq</th>\n",
       "      <td>-0.014937</td>\n",
       "      <td>-0.090799</td>\n",
       "      <td>0.055193</td>\n",
       "      <td>-0.021786</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089753</td>\n",
       "      <td>0.096818</td>\n",
       "      <td>0.769891</td>\n",
       "      <td>0.188792</td>\n",
       "      <td>-0.038662</td>\n",
       "      <td>-0.037520</td>\n",
       "      <td>-0.008382</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>-0.087855</td>\n",
       "      <td>-0.056960</td>\n",
       "      <td>-0.067759</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>0.036882</td>\n",
       "      <td>-0.034699</td>\n",
       "      <td>0.096575</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>0.023008</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.118087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.007989</td>\n",
       "      <td>-0.013874</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>-0.012163</td>\n",
       "      <td>0.089753</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.057874</td>\n",
       "      <td>0.068625</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>0.075643</td>\n",
       "      <td>-0.039299</td>\n",
       "      <td>0.012635</td>\n",
       "      <td>-0.022835</td>\n",
       "      <td>-0.025499</td>\n",
       "      <td>-0.024406</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.014118</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>-0.006254</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.022553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>area_percentage</th>\n",
       "      <td>-0.001444</td>\n",
       "      <td>0.071219</td>\n",
       "      <td>-0.046722</td>\n",
       "      <td>-0.005929</td>\n",
       "      <td>0.096818</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.187377</td>\n",
       "      <td>0.022002</td>\n",
       "      <td>-0.233701</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>0.078095</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>0.212998</td>\n",
       "      <td>-0.051661</td>\n",
       "      <td>-0.031573</td>\n",
       "      <td>0.197111</td>\n",
       "      <td>0.213068</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.081318</td>\n",
       "      <td>0.128234</td>\n",
       "      <td>-0.013784</td>\n",
       "      <td>0.172539</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.022448</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>-0.129847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height_percentage</th>\n",
       "      <td>-0.004994</td>\n",
       "      <td>-0.059720</td>\n",
       "      <td>0.037356</td>\n",
       "      <td>-0.027790</td>\n",
       "      <td>0.769891</td>\n",
       "      <td>0.057874</td>\n",
       "      <td>0.187377</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162984</td>\n",
       "      <td>-0.111932</td>\n",
       "      <td>-0.015018</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>0.220815</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.048081</td>\n",
       "      <td>-0.065646</td>\n",
       "      <td>0.080277</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>0.077086</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>-0.005531</td>\n",
       "      <td>0.117339</td>\n",
       "      <td>0.087908</td>\n",
       "      <td>0.037845</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.025724</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.047740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <td>-0.012055</td>\n",
       "      <td>-0.033513</td>\n",
       "      <td>0.034773</td>\n",
       "      <td>-0.008250</td>\n",
       "      <td>0.188792</td>\n",
       "      <td>0.068625</td>\n",
       "      <td>0.022002</td>\n",
       "      <td>0.162984</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.310400</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>-0.007747</td>\n",
       "      <td>0.325315</td>\n",
       "      <td>-0.047991</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>-0.042928</td>\n",
       "      <td>-0.036580</td>\n",
       "      <td>0.053458</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>-0.016078</td>\n",
       "      <td>-0.005475</td>\n",
       "      <td>-0.016457</td>\n",
       "      <td>-0.004536</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>-0.004087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004087</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>0.058492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <td>0.017126</td>\n",
       "      <td>-0.140193</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.015004</td>\n",
       "      <td>-0.038662</td>\n",
       "      <td>-0.001579</td>\n",
       "      <td>-0.233701</td>\n",
       "      <td>-0.111932</td>\n",
       "      <td>-0.310400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036655</td>\n",
       "      <td>-0.102991</td>\n",
       "      <td>-0.375712</td>\n",
       "      <td>-0.468196</td>\n",
       "      <td>-0.038111</td>\n",
       "      <td>-0.066493</td>\n",
       "      <td>-0.229778</td>\n",
       "      <td>-0.221648</td>\n",
       "      <td>-0.040946</td>\n",
       "      <td>-0.005057</td>\n",
       "      <td>-0.087471</td>\n",
       "      <td>0.054132</td>\n",
       "      <td>-0.162911</td>\n",
       "      <td>-0.107076</td>\n",
       "      <td>-0.036840</td>\n",
       "      <td>-0.029855</td>\n",
       "      <td>-0.033275</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.283512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <td>-0.000483</td>\n",
       "      <td>0.014385</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>-0.037520</td>\n",
       "      <td>-0.003384</td>\n",
       "      <td>-0.002538</td>\n",
       "      <td>-0.015018</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>-0.036655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>-0.033581</td>\n",
       "      <td>-0.040651</td>\n",
       "      <td>0.125555</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>-0.021646</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>-0.011148</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>-0.006170</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.068466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <td>-0.000758</td>\n",
       "      <td>0.020488</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>-0.008382</td>\n",
       "      <td>-0.012002</td>\n",
       "      <td>0.078095</td>\n",
       "      <td>0.011251</td>\n",
       "      <td>-0.007747</td>\n",
       "      <td>-0.102991</td>\n",
       "      <td>0.037433</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>0.067757</td>\n",
       "      <td>0.021766</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.082208</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>-0.016018</td>\n",
       "      <td>0.040357</td>\n",
       "      <td>-0.021564</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>-0.003437</td>\n",
       "      <td>-0.001774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>-0.051779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <td>-0.009615</td>\n",
       "      <td>-0.039078</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>-0.018505</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.075643</td>\n",
       "      <td>0.048875</td>\n",
       "      <td>0.220815</td>\n",
       "      <td>0.325315</td>\n",
       "      <td>-0.375712</td>\n",
       "      <td>-0.033581</td>\n",
       "      <td>-0.003882</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>-0.039679</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>0.026378</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>-0.017454</td>\n",
       "      <td>-0.042676</td>\n",
       "      <td>0.014616</td>\n",
       "      <td>0.025580</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>0.019872</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>-0.008675</td>\n",
       "      <td>0.019269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.135004</td>\n",
       "      <td>-0.078566</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>-0.087855</td>\n",
       "      <td>-0.039299</td>\n",
       "      <td>0.212998</td>\n",
       "      <td>-0.001434</td>\n",
       "      <td>-0.047991</td>\n",
       "      <td>-0.468196</td>\n",
       "      <td>-0.040651</td>\n",
       "      <td>0.067757</td>\n",
       "      <td>0.017331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062492</td>\n",
       "      <td>-0.059684</td>\n",
       "      <td>0.152811</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>-0.004346</td>\n",
       "      <td>-0.024764</td>\n",
       "      <td>0.076648</td>\n",
       "      <td>-0.053682</td>\n",
       "      <td>0.151479</td>\n",
       "      <td>0.093473</td>\n",
       "      <td>0.040165</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>0.031105</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.254516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <td>-0.008597</td>\n",
       "      <td>0.139619</td>\n",
       "      <td>-0.023487</td>\n",
       "      <td>-0.005648</td>\n",
       "      <td>-0.056960</td>\n",
       "      <td>0.012635</td>\n",
       "      <td>-0.051661</td>\n",
       "      <td>-0.048081</td>\n",
       "      <td>0.012284</td>\n",
       "      <td>-0.038111</td>\n",
       "      <td>0.125555</td>\n",
       "      <td>0.021766</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>-0.062492</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441018</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>-0.068138</td>\n",
       "      <td>0.095670</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>-0.013453</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>-0.024725</td>\n",
       "      <td>-0.023425</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>-0.006464</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.007639</td>\n",
       "      <td>-0.021655</td>\n",
       "      <td>-0.070487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <td>-0.005350</td>\n",
       "      <td>0.074938</td>\n",
       "      <td>-0.032875</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>-0.067759</td>\n",
       "      <td>-0.022835</td>\n",
       "      <td>-0.031573</td>\n",
       "      <td>-0.065646</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>-0.066493</td>\n",
       "      <td>0.065832</td>\n",
       "      <td>-0.001238</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>-0.059684</td>\n",
       "      <td>0.441018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>-0.038554</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.009028</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>-0.029789</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>-0.005472</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>-0.007823</td>\n",
       "      <td>-0.004039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004039</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>-0.067625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <td>-0.006889</td>\n",
       "      <td>0.018178</td>\n",
       "      <td>-0.030467</td>\n",
       "      <td>-0.002820</td>\n",
       "      <td>-0.006244</td>\n",
       "      <td>-0.025499</td>\n",
       "      <td>0.197111</td>\n",
       "      <td>0.080277</td>\n",
       "      <td>-0.042928</td>\n",
       "      <td>-0.229778</td>\n",
       "      <td>0.015862</td>\n",
       "      <td>0.082208</td>\n",
       "      <td>-0.039679</td>\n",
       "      <td>0.152811</td>\n",
       "      <td>-0.021505</td>\n",
       "      <td>0.011565</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.013458</td>\n",
       "      <td>-0.021835</td>\n",
       "      <td>-0.005822</td>\n",
       "      <td>0.104947</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>0.158672</td>\n",
       "      <td>0.091736</td>\n",
       "      <td>0.056275</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>-0.165328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <td>-0.005304</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>-0.041523</td>\n",
       "      <td>-0.008094</td>\n",
       "      <td>0.036882</td>\n",
       "      <td>-0.024406</td>\n",
       "      <td>0.213068</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>-0.036580</td>\n",
       "      <td>-0.221648</td>\n",
       "      <td>-0.021646</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>-0.026901</td>\n",
       "      <td>0.128834</td>\n",
       "      <td>-0.068138</td>\n",
       "      <td>-0.038554</td>\n",
       "      <td>-0.013458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>-0.015558</td>\n",
       "      <td>0.096132</td>\n",
       "      <td>-0.031470</td>\n",
       "      <td>0.138911</td>\n",
       "      <td>0.126401</td>\n",
       "      <td>0.059785</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>-0.179305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <td>-0.006948</td>\n",
       "      <td>0.013389</td>\n",
       "      <td>-0.020258</td>\n",
       "      <td>-0.009593</td>\n",
       "      <td>-0.034699</td>\n",
       "      <td>-0.003100</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>-0.024102</td>\n",
       "      <td>0.053458</td>\n",
       "      <td>-0.040946</td>\n",
       "      <td>0.048316</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>0.026378</td>\n",
       "      <td>-0.004346</td>\n",
       "      <td>0.095670</td>\n",
       "      <td>0.117291</td>\n",
       "      <td>-0.021835</td>\n",
       "      <td>-0.014664</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>-0.003842</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.029640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count_families</th>\n",
       "      <td>-0.001363</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>-0.009028</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.096575</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.081318</td>\n",
       "      <td>0.077086</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>-0.005057</td>\n",
       "      <td>0.010241</td>\n",
       "      <td>-0.016018</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>-0.024764</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>-0.000781</td>\n",
       "      <td>-0.005822</td>\n",
       "      <td>-0.015558</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.047961</td>\n",
       "      <td>-0.049083</td>\n",
       "      <td>-0.021114</td>\n",
       "      <td>0.044856</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>-0.020184</td>\n",
       "      <td>-0.019370</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>-0.027376</td>\n",
       "      <td>0.047707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use</th>\n",
       "      <td>0.008026</td>\n",
       "      <td>-0.011838</td>\n",
       "      <td>-0.012175</td>\n",
       "      <td>0.009824</td>\n",
       "      <td>0.053791</td>\n",
       "      <td>-0.009129</td>\n",
       "      <td>0.128234</td>\n",
       "      <td>0.093052</td>\n",
       "      <td>-0.016078</td>\n",
       "      <td>-0.087471</td>\n",
       "      <td>0.001549</td>\n",
       "      <td>0.040357</td>\n",
       "      <td>-0.017454</td>\n",
       "      <td>0.076648</td>\n",
       "      <td>-0.013453</td>\n",
       "      <td>-0.009028</td>\n",
       "      <td>0.104947</td>\n",
       "      <td>0.096132</td>\n",
       "      <td>0.013311</td>\n",
       "      <td>-0.047961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745239</td>\n",
       "      <td>0.520312</td>\n",
       "      <td>0.245023</td>\n",
       "      <td>0.092313</td>\n",
       "      <td>0.055369</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>0.036909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036909</td>\n",
       "      <td>0.224433</td>\n",
       "      <td>-0.076765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_agriculture</th>\n",
       "      <td>0.008090</td>\n",
       "      <td>-0.017949</td>\n",
       "      <td>0.011190</td>\n",
       "      <td>0.017037</td>\n",
       "      <td>-0.005484</td>\n",
       "      <td>-0.001919</td>\n",
       "      <td>-0.013784</td>\n",
       "      <td>-0.005531</td>\n",
       "      <td>-0.005475</td>\n",
       "      <td>0.054132</td>\n",
       "      <td>0.017506</td>\n",
       "      <td>-0.021564</td>\n",
       "      <td>-0.042676</td>\n",
       "      <td>-0.053682</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>-0.026775</td>\n",
       "      <td>-0.031470</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>-0.049083</td>\n",
       "      <td>0.745239</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048553</td>\n",
       "      <td>-0.022865</td>\n",
       "      <td>-0.008614</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>-0.006671</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.008853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>-0.012675</td>\n",
       "      <td>0.005914</td>\n",
       "      <td>0.070755</td>\n",
       "      <td>-0.014118</td>\n",
       "      <td>0.172539</td>\n",
       "      <td>0.117339</td>\n",
       "      <td>-0.016457</td>\n",
       "      <td>-0.162911</td>\n",
       "      <td>-0.011148</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.014616</td>\n",
       "      <td>0.151479</td>\n",
       "      <td>-0.024725</td>\n",
       "      <td>-0.029789</td>\n",
       "      <td>0.158672</td>\n",
       "      <td>0.138911</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>-0.021114</td>\n",
       "      <td>0.520312</td>\n",
       "      <td>-0.048553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015964</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>-0.003607</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.091262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <td>-0.006756</td>\n",
       "      <td>0.024592</td>\n",
       "      <td>-0.034872</td>\n",
       "      <td>-0.016650</td>\n",
       "      <td>0.057665</td>\n",
       "      <td>0.003328</td>\n",
       "      <td>0.100113</td>\n",
       "      <td>0.087908</td>\n",
       "      <td>-0.004536</td>\n",
       "      <td>-0.107076</td>\n",
       "      <td>-0.010944</td>\n",
       "      <td>0.029079</td>\n",
       "      <td>0.025580</td>\n",
       "      <td>0.093473</td>\n",
       "      <td>-0.023425</td>\n",
       "      <td>-0.009257</td>\n",
       "      <td>0.091736</td>\n",
       "      <td>0.126401</td>\n",
       "      <td>-0.001656</td>\n",
       "      <td>0.044856</td>\n",
       "      <td>0.245023</td>\n",
       "      <td>-0.022865</td>\n",
       "      <td>-0.015964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>-0.001699</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>-0.074737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <td>0.000234</td>\n",
       "      <td>-0.003183</td>\n",
       "      <td>-0.005908</td>\n",
       "      <td>-0.011057</td>\n",
       "      <td>0.023008</td>\n",
       "      <td>-0.006254</td>\n",
       "      <td>0.057857</td>\n",
       "      <td>0.037845</td>\n",
       "      <td>-0.001054</td>\n",
       "      <td>-0.036840</td>\n",
       "      <td>-0.006170</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.006679</td>\n",
       "      <td>0.040165</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>-0.005472</td>\n",
       "      <td>0.056275</td>\n",
       "      <td>0.059785</td>\n",
       "      <td>-0.003842</td>\n",
       "      <td>-0.011535</td>\n",
       "      <td>0.092313</td>\n",
       "      <td>-0.008614</td>\n",
       "      <td>-0.006014</td>\n",
       "      <td>-0.002832</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>-0.042517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.010084</td>\n",
       "      <td>-0.021183</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>0.005546</td>\n",
       "      <td>-0.005331</td>\n",
       "      <td>0.039799</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.001506</td>\n",
       "      <td>-0.029855</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>-0.002662</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>0.019143</td>\n",
       "      <td>-0.006464</td>\n",
       "      <td>0.001655</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.015289</td>\n",
       "      <td>-0.002304</td>\n",
       "      <td>-0.020184</td>\n",
       "      <td>0.055369</td>\n",
       "      <td>-0.005167</td>\n",
       "      <td>-0.003607</td>\n",
       "      <td>-0.001699</td>\n",
       "      <td>-0.000640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.001556</td>\n",
       "      <td>-0.018233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <td>0.000844</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.003235</td>\n",
       "      <td>-0.010094</td>\n",
       "      <td>-0.006739</td>\n",
       "      <td>-0.002185</td>\n",
       "      <td>0.022448</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>-0.033275</td>\n",
       "      <td>-0.004778</td>\n",
       "      <td>-0.003437</td>\n",
       "      <td>0.019872</td>\n",
       "      <td>0.031105</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>-0.007823</td>\n",
       "      <td>0.019059</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>0.011563</td>\n",
       "      <td>-0.019370</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>-0.006671</td>\n",
       "      <td>-0.004658</td>\n",
       "      <td>-0.002193</td>\n",
       "      <td>-0.000826</td>\n",
       "      <td>-0.000496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.015658</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>0.019111</td>\n",
       "      <td>0.025724</td>\n",
       "      <td>-0.004087</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>-0.001774</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>0.008638</td>\n",
       "      <td>-0.000146</td>\n",
       "      <td>-0.004039</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>0.036909</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <td>-0.003080</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.001765</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.006687</td>\n",
       "      <td>-0.001409</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>-0.004087</td>\n",
       "      <td>-0.007992</td>\n",
       "      <td>-0.002467</td>\n",
       "      <td>0.022704</td>\n",
       "      <td>-0.003539</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.007639</td>\n",
       "      <td>-0.004039</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>-0.001628</td>\n",
       "      <td>-0.001536</td>\n",
       "      <td>-0.015182</td>\n",
       "      <td>0.036909</td>\n",
       "      <td>-0.003444</td>\n",
       "      <td>-0.002405</td>\n",
       "      <td>-0.001132</td>\n",
       "      <td>-0.000427</td>\n",
       "      <td>-0.000256</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.000171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>-0.005028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <td>0.001657</td>\n",
       "      <td>-0.023249</td>\n",
       "      <td>-0.008772</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.002443</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>-0.009689</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>-0.000190</td>\n",
       "      <td>0.037814</td>\n",
       "      <td>-0.008675</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>-0.021655</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.007701</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.027376</td>\n",
       "      <td>0.224433</td>\n",
       "      <td>0.092996</td>\n",
       "      <td>0.012682</td>\n",
       "      <td>-0.000608</td>\n",
       "      <td>0.013962</td>\n",
       "      <td>-0.001556</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.001037</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.027039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>damage_grade</th>\n",
       "      <td>-0.000994</td>\n",
       "      <td>-0.068103</td>\n",
       "      <td>0.051701</td>\n",
       "      <td>-0.001693</td>\n",
       "      <td>0.118087</td>\n",
       "      <td>0.022553</td>\n",
       "      <td>-0.129847</td>\n",
       "      <td>0.047740</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.283512</td>\n",
       "      <td>0.068466</td>\n",
       "      <td>-0.051779</td>\n",
       "      <td>0.019269</td>\n",
       "      <td>-0.254516</td>\n",
       "      <td>-0.070487</td>\n",
       "      <td>-0.067625</td>\n",
       "      <td>-0.165328</td>\n",
       "      <td>-0.179305</td>\n",
       "      <td>-0.029640</td>\n",
       "      <td>0.047707</td>\n",
       "      <td>-0.076765</td>\n",
       "      <td>0.008853</td>\n",
       "      <td>-0.091262</td>\n",
       "      <td>-0.074737</td>\n",
       "      <td>-0.042517</td>\n",
       "      <td>-0.018233</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>-0.027039</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        building_id  ...  damage_grade\n",
       "building_id                                1.000000  ...     -0.000994\n",
       "geo_level_1_id                             0.000737  ...     -0.068103\n",
       "geo_level_2_id                            -0.004609  ...      0.051701\n",
       "geo_level_3_id                            -0.004742  ...     -0.001693\n",
       "count_floors_pre_eq                       -0.014937  ...      0.118087\n",
       "age                                       -0.007989  ...      0.022553\n",
       "area_percentage                           -0.001444  ...     -0.129847\n",
       "height_percentage                         -0.004994  ...      0.047740\n",
       "has_superstructure_adobe_mud              -0.012055  ...      0.058492\n",
       "has_superstructure_mud_mortar_stone        0.017126  ...      0.283512\n",
       "has_superstructure_stone_flag             -0.000483  ...      0.068466\n",
       "has_superstructure_cement_mortar_stone    -0.000758  ...     -0.051779\n",
       "has_superstructure_mud_mortar_brick       -0.009615  ...      0.019269\n",
       "has_superstructure_cement_mortar_brick     0.003796  ...     -0.254516\n",
       "has_superstructure_timber                 -0.008597  ...     -0.070487\n",
       "has_superstructure_bamboo                 -0.005350  ...     -0.067625\n",
       "has_superstructure_rc_non_engineered      -0.006889  ...     -0.165328\n",
       "has_superstructure_rc_engineered          -0.005304  ...     -0.179305\n",
       "has_superstructure_other                  -0.006948  ...     -0.029640\n",
       "count_families                            -0.001363  ...      0.047707\n",
       "has_secondary_use                          0.008026  ...     -0.076765\n",
       "has_secondary_use_agriculture              0.008090  ...      0.008853\n",
       "has_secondary_use_hotel                    0.004440  ...     -0.091262\n",
       "has_secondary_use_rental                  -0.006756  ...     -0.074737\n",
       "has_secondary_use_institution              0.000234  ...     -0.042517\n",
       "has_secondary_use_school                   0.000339  ...     -0.018233\n",
       "has_secondary_use_industry                 0.000844  ...     -0.012500\n",
       "has_secondary_use_health_post              0.002841  ...     -0.005028\n",
       "has_secondary_use_gov_office                    NaN  ...           NaN\n",
       "has_secondary_use_use_police              -0.003080  ...     -0.005028\n",
       "has_secondary_use_other                    0.001657  ...     -0.027039\n",
       "damage_grade                              -0.000994  ...      1.000000\n",
       "\n",
       "[32 rows x 32 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Correlation of independent variables from dataset\n",
    "df_sub.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RCRvpMOkwr3s"
   },
   "source": [
    "1.\tList which features you will choose in this model. Write a brief statement: Is it required to consider the repeating features in the model? if independent variables are highly correlated. Select the required columns in the dataframe and drop the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70cTnywyzG6-"
   },
   "source": [
    "height_percentage and count_floors_pre_eq are highly correlated with 0.774706. has_secondary_use is correlated with has_secondary_use_agriculture having 0.748286. Hence dropping count_floors_pre_eq, has_secondary_use_agriculture and building_id as it does not relevant information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "5Y3amR-Wtyrn",
    "outputId": "08d7d180-f61b-4b90-9efc-e122f50cd78f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>position</th>\n",
       "      <th>plan_configuration</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>legal_ownership_status</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93841</th>\n",
       "      <td>12</td>\n",
       "      <td>1010</td>\n",
       "      <td>7775</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92054</th>\n",
       "      <td>0</td>\n",
       "      <td>858</td>\n",
       "      <td>2681</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>x</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41385</th>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "      <td>6570</td>\n",
       "      <td>40</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       geo_level_1_id  geo_level_2_id  ...  has_secondary_use_other  damage_grade\n",
       "93841              12            1010  ...                        0             2\n",
       "92054               0             858  ...                        0             2\n",
       "41385               0             946  ...                        0             2\n",
       "\n",
       "[3 rows x 37 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping unnecessary column\n",
    "df_sub = df_sub.drop('count_floors_pre_eq',axis=1)\n",
    "df_sub = df_sub.drop('has_secondary_use_agriculture',axis=1)\n",
    "df_sub = df_sub.drop('building_id',axis=1)\n",
    "df_sub.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cnFN3T8owTQC"
   },
   "source": [
    "2.1 Convert percentage to value/100 (check which option gives better result, as-is or divided/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 215
    },
    "id": "of8O2K-WCp9T",
    "outputId": "e2b3c0a1-ac94-4c7f-9a25-dfece860e9a8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>position</th>\n",
       "      <th>plan_configuration</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>legal_ownership_status</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "      <th>damage_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93841</th>\n",
       "      <td>12</td>\n",
       "      <td>1010</td>\n",
       "      <td>7775</td>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92054</th>\n",
       "      <td>0</td>\n",
       "      <td>858</td>\n",
       "      <td>2681</td>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>n</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>x</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41385</th>\n",
       "      <td>0</td>\n",
       "      <td>946</td>\n",
       "      <td>6570</td>\n",
       "      <td>40</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184953</th>\n",
       "      <td>6</td>\n",
       "      <td>697</td>\n",
       "      <td>5406</td>\n",
       "      <td>25</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>o</td>\n",
       "      <td>r</td>\n",
       "      <td>q</td>\n",
       "      <td>f</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124935</th>\n",
       "      <td>5</td>\n",
       "      <td>1284</td>\n",
       "      <td>3604</td>\n",
       "      <td>15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.08</td>\n",
       "      <td>t</td>\n",
       "      <td>r</td>\n",
       "      <td>n</td>\n",
       "      <td>x</td>\n",
       "      <td>q</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>v</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geo_level_1_id  geo_level_2_id  ...  has_secondary_use_other  damage_grade\n",
       "93841               12            1010  ...                        0             2\n",
       "92054                0             858  ...                        0             2\n",
       "41385                0             946  ...                        0             2\n",
       "184953               6             697  ...                        0             2\n",
       "124935               5            1284  ...                        0             2\n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting % values by dividing it to 100\n",
    "\n",
    "df_sub['area_percentage'] = df_sub['area_percentage'].div(100).round(3)\n",
    "df_sub['height_percentage'] = df_sub['height_percentage'].div(100).round(3)\n",
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEsEy3OZwbG5"
   },
   "source": [
    "2.2\tMake an 80-20 stratified split based on the target variable(categorical variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "Eps8AxsdsvNo"
   },
   "outputs": [],
   "source": [
    "X = df_sub.drop(['damage_grade'],axis=1)\n",
    "y = df_sub[['damage_grade']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                        random_state=42, stratify=y['damage_grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJaopMt5xCev"
   },
   "source": [
    "2.3\tShow the stratified split on merged dataset, train and test set.(display the ratio of classes on each dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "id": "_xBZ3OwhtF3T",
    "outputId": "258e2ecc-48a7-4181-f77d-9e2a45dec23c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    0.571374\n",
      "3    0.331926\n",
      "1    0.096700\n",
      "Name: damage_grade, dtype: float64 2    0.571391\n",
      "3    0.331930\n",
      "1    0.096680\n",
      "Name: damage_grade, dtype: float64 2    0.571307\n",
      "3    0.331912\n",
      "1    0.096781\n",
      "Name: damage_grade, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y['damage_grade'].value_counts()/len(y),y_train['damage_grade'].value_counts()/len(y_train),y_test['damage_grade'].value_counts()/len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "id": "vYKHmnXOGbTP",
    "outputId": "15bbb94f-2305-483d-8ad8-e253ae248e1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo_level_1_id                              int64\n",
       "geo_level_2_id                              int64\n",
       "geo_level_3_id                              int64\n",
       "age                                         int64\n",
       "area_percentage                           float64\n",
       "height_percentage                         float64\n",
       "land_surface_condition                     object\n",
       "foundation_type                            object\n",
       "roof_type                                  object\n",
       "ground_floor_type                          object\n",
       "other_floor_type                           object\n",
       "position                                   object\n",
       "plan_configuration                         object\n",
       "has_superstructure_adobe_mud                int64\n",
       "has_superstructure_mud_mortar_stone         int64\n",
       "has_superstructure_stone_flag               int64\n",
       "has_superstructure_cement_mortar_stone      int64\n",
       "has_superstructure_mud_mortar_brick         int64\n",
       "has_superstructure_cement_mortar_brick      int64\n",
       "has_superstructure_timber                   int64\n",
       "has_superstructure_bamboo                   int64\n",
       "has_superstructure_rc_non_engineered        int64\n",
       "has_superstructure_rc_engineered            int64\n",
       "has_superstructure_other                    int64\n",
       "legal_ownership_status                     object\n",
       "count_families                              int64\n",
       "has_secondary_use                           int64\n",
       "has_secondary_use_hotel                     int64\n",
       "has_secondary_use_rental                    int64\n",
       "has_secondary_use_institution               int64\n",
       "has_secondary_use_school                    int64\n",
       "has_secondary_use_industry                  int64\n",
       "has_secondary_use_health_post               int64\n",
       "has_secondary_use_gov_office                int64\n",
       "has_secondary_use_use_police                int64\n",
       "has_secondary_use_other                     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 238,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rtBD-uFxrF2"
   },
   "source": [
    "2.4\tEncode the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0QFPIEvxxrcH",
    "outputId": "e8f79c5f-40d5-43c7-9b7b-fa8e441844ac"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#encoding all the categorical variables:\n",
    "le = LabelEncoder()\n",
    "\n",
    "#Train set scaling\n",
    "X_train[\"land_surface_condition\"] = le.fit_transform(X_train[\"land_surface_condition\"])\n",
    "X_test[\"land_surface_condition\"]= le.transform(X_test[\"land_surface_condition\"])\n",
    "\n",
    "X_train[\"foundation_type\"] = le.fit_transform(X_train[\"foundation_type\"])\n",
    "X_test[\"foundation_type\"]= le.transform(X_test[\"foundation_type\"])\n",
    "\n",
    "X_train[\"roof_type\"] = le.fit_transform(X_train[\"roof_type\"])\n",
    "X_test[\"roof_type\"]= le.transform(X_test[\"roof_type\"])\n",
    "\n",
    "X_train[\"ground_floor_type\"] = le.fit_transform(X_train[\"ground_floor_type\"])\n",
    "X_test[\"ground_floor_type\"]= le.transform(X_test[\"ground_floor_type\"])\n",
    "\n",
    "X_train[\"other_floor_type\"] = le.fit_transform(X_train[\"other_floor_type\"])\n",
    "X_test[\"other_floor_type\"]= le.transform(X_test[\"other_floor_type\"])\n",
    "\n",
    "\n",
    "X_train[\"position\"] = le.fit_transform(X_train[\"position\"])\n",
    "X_test[\"position\"]= le.transform(X_test[\"position\"])\n",
    "\n",
    "X_train[\"plan_configuration\"] = le.fit_transform(X_train[\"plan_configuration\"])\n",
    "X_test[\"plan_configuration\"]= le.transform(X_test[\"plan_configuration\"])\n",
    "\n",
    "X_train[\"legal_ownership_status\"] = le.fit_transform(X_train[\"legal_ownership_status\"])\n",
    "X_test[\"legal_ownership_status\"]= le.transform(X_test[\"legal_ownership_status\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2xcQWlTxRiv"
   },
   "source": [
    "2.5\tStandardize the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "Dph3Nq_Hta7p",
    "outputId": "28bb3543-7bde-444b-c6bb-487a727c9510"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geo_level_1_id',\n",
       " 'geo_level_2_id',\n",
       " 'geo_level_3_id',\n",
       " 'age',\n",
       " 'area_percentage',\n",
       " 'height_percentage',\n",
       " 'land_surface_condition',\n",
       " 'foundation_type',\n",
       " 'roof_type',\n",
       " 'ground_floor_type',\n",
       " 'other_floor_type',\n",
       " 'position',\n",
       " 'plan_configuration',\n",
       " 'legal_ownership_status',\n",
       " 'count_families']"
      ]
     },
     "execution_count": 240,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nc = X_train.columns[X_train.dtypes.apply(lambda c: np.issubdtype(c, np.number))]\n",
    "nc = [x for x in nc if 'has_' not in x]\n",
    "nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "6BitqjdQtdDe",
    "outputId": "cc0ad762-9664-491e-c734-2c1f9bc37410"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.6/dist-packages/pandas/core/indexing.py:1736: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  isetter(loc, value[:, i].tolist())\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train[nc] = scaler.fit_transform(X_train[nc])\n",
    "X_test[nc] = scaler.fit_transform(X_test[nc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "nMfdOQ9pKwbg",
    "outputId": "afe2595d-bd12-4660-a4c8-5625806bb3e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_level_1_id</th>\n",
       "      <th>geo_level_2_id</th>\n",
       "      <th>geo_level_3_id</th>\n",
       "      <th>age</th>\n",
       "      <th>area_percentage</th>\n",
       "      <th>height_percentage</th>\n",
       "      <th>land_surface_condition</th>\n",
       "      <th>foundation_type</th>\n",
       "      <th>roof_type</th>\n",
       "      <th>ground_floor_type</th>\n",
       "      <th>other_floor_type</th>\n",
       "      <th>position</th>\n",
       "      <th>plan_configuration</th>\n",
       "      <th>has_superstructure_adobe_mud</th>\n",
       "      <th>has_superstructure_mud_mortar_stone</th>\n",
       "      <th>has_superstructure_stone_flag</th>\n",
       "      <th>has_superstructure_cement_mortar_stone</th>\n",
       "      <th>has_superstructure_mud_mortar_brick</th>\n",
       "      <th>has_superstructure_cement_mortar_brick</th>\n",
       "      <th>has_superstructure_timber</th>\n",
       "      <th>has_superstructure_bamboo</th>\n",
       "      <th>has_superstructure_rc_non_engineered</th>\n",
       "      <th>has_superstructure_rc_engineered</th>\n",
       "      <th>has_superstructure_other</th>\n",
       "      <th>legal_ownership_status</th>\n",
       "      <th>count_families</th>\n",
       "      <th>has_secondary_use</th>\n",
       "      <th>has_secondary_use_hotel</th>\n",
       "      <th>has_secondary_use_rental</th>\n",
       "      <th>has_secondary_use_institution</th>\n",
       "      <th>has_secondary_use_school</th>\n",
       "      <th>has_secondary_use_industry</th>\n",
       "      <th>has_secondary_use_health_post</th>\n",
       "      <th>has_secondary_use_gov_office</th>\n",
       "      <th>has_secondary_use_use_police</th>\n",
       "      <th>has_secondary_use_other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14278</th>\n",
       "      <td>-0.728497</td>\n",
       "      <td>1.633724</td>\n",
       "      <td>0.553108</td>\n",
       "      <td>0.107105</td>\n",
       "      <td>-0.476939</td>\n",
       "      <td>-0.227510</td>\n",
       "      <td>0.436309</td>\n",
       "      <td>-0.214239</td>\n",
       "      <td>-0.607978</td>\n",
       "      <td>-0.479642</td>\n",
       "      <td>1.962004</td>\n",
       "      <td>-0.092425</td>\n",
       "      <td>-0.192162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124912</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111267</th>\n",
       "      <td>0.763458</td>\n",
       "      <td>-1.056480</td>\n",
       "      <td>-0.607579</td>\n",
       "      <td>-0.224986</td>\n",
       "      <td>-0.003532</td>\n",
       "      <td>0.297813</td>\n",
       "      <td>0.436309</td>\n",
       "      <td>3.196673</td>\n",
       "      <td>1.073056</td>\n",
       "      <td>-0.479642</td>\n",
       "      <td>-0.249922</td>\n",
       "      <td>-0.092425</td>\n",
       "      <td>-0.192162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124912</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215865</th>\n",
       "      <td>0.390469</td>\n",
       "      <td>-0.608919</td>\n",
       "      <td>0.926675</td>\n",
       "      <td>-0.224986</td>\n",
       "      <td>-1.187048</td>\n",
       "      <td>-0.227510</td>\n",
       "      <td>0.436309</td>\n",
       "      <td>-0.214239</td>\n",
       "      <td>1.073056</td>\n",
       "      <td>-0.479642</td>\n",
       "      <td>1.962004</td>\n",
       "      <td>1.535898</td>\n",
       "      <td>-0.192162</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124912</td>\n",
       "      <td>0.029349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        geo_level_1_id  ...  has_secondary_use_other\n",
       "14278        -0.728497  ...                        0\n",
       "111267        0.763458  ...                        0\n",
       "215865        0.390469  ...                        0\n",
       "\n",
       "[3 rows x 36 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the train set\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "th83LUd6yOw1"
   },
   "source": [
    "3\tBuild a SVM Classifier, train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "cjuoCgFbrPV-",
    "outputId": "2b6c544a-0eb6-44bb-b951-1f0f7405cffe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=42, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 243,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(kernel='rbf',random_state = 42) \n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "id": "uLfD1NeLrPYB"
   },
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6Ga0lCiyVWS"
   },
   "source": [
    "3.1\tEvaluate your model based on applicable metrics. Show the metric(s) you chose and why you chose this(these) metrics.\n",
    "\n",
    "Choosing confusion matrix and classification report as accuracy is generally not the preferred performance measure for classifiers. A much better way to evaluate the performance of a classifier is to look at the confusion matrix.\n",
    "\n",
    "The confusion matrix gives a lot of information, but sometimes we may prefer a more concise metric. \n",
    "\n",
    "It is often convenient to combine precision and recall into a single metric called the F1 score, in particular, if you need a simple way to compare two classifiers. \n",
    "The F1 score is the harmonic mean of precision and recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "AEdhWElCrPbA",
    "outputId": "904a44b3-2933-4dc7-a4d2-0b0ffc0a7014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 123  319   12]\n",
      " [  71 2410  199]\n",
      " [   5 1205  347]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.27      0.38       454\n",
      "           2       0.61      0.90      0.73      2680\n",
      "           3       0.62      0.22      0.33      1557\n",
      "\n",
      "    accuracy                           0.61      4691\n",
      "   macro avg       0.62      0.46      0.48      4691\n",
      "weighted avg       0.62      0.61      0.56      4691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1PqHlrmykKZ"
   },
   "source": [
    "3.2\tList the hyper-parameters that can be tuned in SVM Classifier. Explain the meaning of each hyper-parameter. Show the code along with comments on the parameter value chosen (use class presentation, discussion notes, some online reading) and why this value was chosen. Show the improvement you achieved in model accuracy.\n",
    "\n",
    "Ans: Changing kernel to poly, degree to 3 , 10 independent kernels , c =3 to check the accuracy. \n",
    "The strength of the regularization is inversely proportional to C. Must be strictly positive. The penalty is a squared l2 penalty. The low c to have strong regularisation\n",
    "\n",
    "The accuracy of 62% after tuning the hyper parameters makes this the best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "CVb6eO4rrPdl",
    "outputId": "bf85f954-f32e-499b-a3f6-562454ba47e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=3, break_ties=False, cache_size=200, class_weight=None, coef0=10,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='poly',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 246,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = SVC(kernel=\"poly\", degree=3, coef0=10, C=3) \n",
    "clf1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "id": "0-XaI-XYrPgR"
   },
   "outputs": [],
   "source": [
    "y_pred1 = clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "MT-n-Wu3rPie",
    "outputId": "b26ee5cb-11d4-41e2-d78c-1b4b9bf3f6c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 165  262   27]\n",
      " [ 148 2190  342]\n",
      " [  19 1057  481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.36      0.42       454\n",
      "           2       0.62      0.82      0.71      2680\n",
      "           3       0.57      0.31      0.40      1557\n",
      "\n",
      "    accuracy                           0.60      4691\n",
      "   macro avg       0.56      0.50      0.51      4691\n",
      "weighted avg       0.59      0.60      0.58      4691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(classification_report(y_test,y_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVOeBUZW3zo2"
   },
   "source": [
    "4\tBuild a Decision Tree Classifier, train the model\n",
    "\n",
    "4.1\tEvaluate your model based on applicable metrics. Show the metric(s) you chose and why you chose this(these) metrics.\n",
    "\n",
    "Choosing confusion matrix and classification report as accuracy is generally not the preferred performance measure for classifiers. A much better way to evaluate the performance of a classifier is to look at the confusion matrix.\n",
    "\n",
    "The confusion matrix gives you a lot of information, but sometimes you may prefer a more concise metric. \n",
    "\n",
    "It is often convenient to combine precision and recall into a single metric called the F1 score, in particular, if you need a simple way to compare two classifiers. \n",
    "The F1 score is the harmonic mean of precision and recall "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "id": "A5nE65AWrPlz",
    "outputId": "6e06bfcc-a75b-4749-fb9d-bcaa7fc21fe2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 249,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier = DecisionTreeClassifier(random_state=42)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "id": "QD00ymJUrPsg"
   },
   "outputs": [],
   "source": [
    "y_pred2= classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "uw6KMjbwrPvc",
    "outputId": "a6d16a42-5655-4996-fd65-4ee1265cddec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 165  262   27]\n",
      " [ 148 2190  342]\n",
      " [  19 1057  481]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.43      0.42       454\n",
      "           2       0.67      0.64      0.65      2680\n",
      "           3       0.54      0.57      0.55      1557\n",
      "\n",
      "    accuracy                           0.60      4691\n",
      "   macro avg       0.54      0.55      0.54      4691\n",
      "weighted avg       0.60      0.60      0.60      4691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHqYX6J44GRU"
   },
   "source": [
    "4.2\tList the hyper-parameters that can be tuned in Decision Tree model . Show the code along with comments on the parameter value chosen (use class presentation, discussion notes, some online reading) and why this value was chosen. Show the improvement you achieved in model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "id": "2jlIKlhYuFSs"
   },
   "outputs": [],
   "source": [
    "dec_clf = DecisionTreeClassifier(random_state=42, max_depth = 5, max_leaf_nodes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "id": "KJKjCPyEuFU8"
   },
   "outputs": [],
   "source": [
    "y_pred3= classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "jblRU1MvuFZy",
    "outputId": "31f3afe1-c5b4-4b8b-c3c6-37c646153e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 193  218   43]\n",
      " [ 250 1715  715]\n",
      " [  32  636  889]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.41      0.43      0.42       454\n",
      "           2       0.67      0.64      0.65      2680\n",
      "           3       0.54      0.57      0.55      1557\n",
      "\n",
      "    accuracy                           0.60      4691\n",
      "   macro avg       0.54      0.55      0.54      4691\n",
      "weighted avg       0.60      0.60      0.60      4691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test,y_pred3))\n",
    "print(classification_report(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6y9glsLy4VaL"
   },
   "source": [
    "3.3\tPlot Learning curve on the optimized model and provide insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "YD8UW_TKuFen",
    "outputId": "93866c16-8586-41a3-a15e-2c4945ac55af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 254,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, X, y, ylim, cv,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, test_scores= learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,scoring='accuracy')\n",
    "    train_scores=np.mean(train_scores,axis=1)\n",
    "    test_scores=np.mean(test_scores,axis=1)\n",
    "    \n",
    "   \n",
    "   \n",
    "    plt.plot(train_sizes, train_scores, 'o-', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "\n",
    " \n",
    "\n",
    "plot_learning_curve(SVC(),X_train, y_train, ylim=(0.3, 1.01),\n",
    "                    cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "haSV-klF6TOY"
   },
   "source": [
    "The learning curve shows the validation and training score of an estimator for varying numbers of training samples. The training score is very high at the beginning and decreases and the cross-validation score is very low at the beginning and increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "g393dzXhuFkr",
    "outputId": "e21589f4-c598-473e-be14-34f0ef56c16b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'matplotlib.pyplot' from '/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py'>"
      ]
     },
     "execution_count": 220,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "def plot_learning_curve(estimator, X, y, ylim, cv,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    train_sizes, train_scores, test_scores= learning_curve(estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "                       train_sizes=train_sizes,scoring='accuracy')\n",
    "    train_scores=np.mean(train_scores,axis=1)\n",
    "    test_scores=np.mean(test_scores,axis=1)\n",
    "    \n",
    "   \n",
    "   \n",
    "    plt.plot(train_sizes, train_scores, 'o-', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=0)\n",
    "\n",
    " \n",
    "\n",
    "plot_learning_curve(SVC(),X_train, y_train, ylim=(0.3, 1.01),\n",
    "                    cv=cv, n_jobs=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pzgc4mAh4l_y"
   },
   "source": [
    "The training score is still around the maximum and the validation score could be increased with more training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "98b1soix8SHi"
   },
   "source": [
    "5. Compare the Model Evaluation metric of which model performed better along with reason why you consider so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LW1WmkjK7ART"
   },
   "source": [
    "In first plot of SVM model, The validation score and the training score converge to a value that is quite low with increasing size of the training set. Thus, we will probably not benefit much from more training data.\n",
    "\n",
    "In contrast, for small amounts of data, the training score of the Decision Tree is much greater than the validation score. Adding more training samples will most likely increase generalization."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DSP_Assignment_Three_EarthQuake_Due_Oct11_1pm (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
